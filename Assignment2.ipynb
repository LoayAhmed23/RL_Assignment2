{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[classic-control] torch wandb\n",
        "!pip install wandb -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyUPDQXy3wOI",
        "outputId": "05874176-3a92-4123-bd53-f0cee3fde38c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: gymnasium[classic-control] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]) (2.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkuoJtoy30tv",
        "outputId": "fc750593-5eda-4729-feb1-f83d0ffbe3d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myousefyousefyousef335\u001b[0m (\u001b[33myousefyousefyousef335-cairo-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carpole and Acrobot"
      ],
      "metadata": {
        "id": "YgAgbUjclZ-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nhHdTPuu3bh6",
        "outputId": "426413b1-bafc-4546-93e7-cdc047f6999d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=========================================\n",
            "    STARTING EXPERIMENTS FOR: CartPole-v1 \n",
            "=========================================\n",
            "\n",
            "\n",
            "--- Starting Run 1/4: DQN_High_LR_High_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_115438-qhyf11yk</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/qhyf11yk' target=\"_blank\">CartPole-v1_DQN_DQN_High_LR_High_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/qhyf11yk' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/qhyf11yk</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for: CartPole-v1_DQN_DQN_High_LR_High_Mem ---\n",
            "Episode 0/500 | Duration: 16 | Epsilon: 0.8873\n",
            "Episode 100/500 | Duration: 51 | Epsilon: 0.0501\n",
            "Episode 200/500 | Duration: 500 | Epsilon: 0.0500\n",
            "Episode 300/500 | Duration: 102 | Epsilon: 0.0500\n",
            "Episode 400/500 | Duration: 500 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 47.48 +/- 36.94\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/CartPole-v1_DQN_DQN_High_LR_High_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to ./videos/CartPole-v1_DQN_DQN_High_LR_High_Mem\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▂▁▂▂▃▄▅▇▆▆▆▆▆▇▇▇█▅▅▄▂▂▂</td></tr><tr><td>duration</td><td>▁▁▁▁▁▇▂██▃▄▅▂▁▃████▁████▁▂▂▁▂▁▂▂▅█▅██▁▄█</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>epsilon</td><td>███▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.12538</td></tr><tr><td>duration</td><td>117</td></tr><tr><td>episode</td><td>499</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>47.48</td></tr><tr><td>test_std_duration</td><td>36.93521</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">CartPole-v1_DQN_DQN_High_LR_High_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/qhyf11yk' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/qhyf11yk</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_115438-qhyf11yk/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Run 2/4: DQN_Low_LR_Low_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_120251-yam26qz4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/yam26qz4' target=\"_blank\">CartPole-v1_DQN_DQN_Low_LR_Low_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/yam26qz4' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/yam26qz4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for: CartPole-v1_DQN_DQN_Low_LR_Low_Mem ---\n",
            "Episode 0/500 | Duration: 14 | Epsilon: 0.8890\n",
            "Episode 100/500 | Duration: 14 | Epsilon: 0.2579\n",
            "Episode 200/500 | Duration: 10 | Epsilon: 0.1090\n",
            "Episode 300/500 | Duration: 171 | Epsilon: 0.0502\n",
            "Episode 400/500 | Duration: 97 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 95.10 +/- 5.12\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/CartPole-v1_DQN_DQN_Low_LR_Low_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to ./videos/CartPole-v1_DQN_DQN_Low_LR_Low_Mem\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▃▂▁▁▂▂▂▂▂▂▃▄▄▄▃▄▄▆▇▅▇▇▇▇█▃▄▄▃▄▄▄▄▄▄▄▄▄▄▃</td></tr><tr><td>duration</td><td>▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▇█▆▇▆▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>episode</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>epsilon</td><td>█▇▆▅▅▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.54274</td></tr><tr><td>duration</td><td>92</td></tr><tr><td>episode</td><td>499</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>95.1</td></tr><tr><td>test_std_duration</td><td>5.11957</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">CartPole-v1_DQN_DQN_Low_LR_Low_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/yam26qz4' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/yam26qz4</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_120251-yam26qz4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Run 3/4: DDQN_High_LR_High_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_120433-tbqxirn3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tbqxirn3' target=\"_blank\">CartPole-v1_DDQN_DDQN_High_LR_High_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tbqxirn3' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tbqxirn3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for: CartPole-v1_DDQN_DDQN_High_LR_High_Mem ---\n",
            "Episode 0/500 | Duration: 10 | Epsilon: 0.8924\n",
            "Episode 100/500 | Duration: 137 | Epsilon: 0.0500\n",
            "Episode 200/500 | Duration: 44 | Epsilon: 0.0500\n",
            "Episode 300/500 | Duration: 26 | Epsilon: 0.0500\n",
            "Episode 400/500 | Duration: 500 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 199.74 +/- 4.92\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/CartPole-v1_DDQN_DDQN_High_LR_High_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to ./videos/CartPole-v1_DDQN_DDQN_High_LR_High_Mem\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▁▁▂▂▃▃▃▂▂▂▃▅▆▄▃▄▆▅▆▆▇▆▇█▇█▆▇▄▄▅▅▃▁▂▃▂▃▂</td></tr><tr><td>duration</td><td>▁▁▁▅▃▂▂▃▃▃▃▂▂▂▃▁▃▃▃▁▂▂▂██▁▁▃▃▃█▂▂▅▁█▅▅█▅</td></tr><tr><td>episode</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>epsilon</td><td>██▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.16193</td></tr><tr><td>duration</td><td>202</td></tr><tr><td>episode</td><td>499</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>199.74</td></tr><tr><td>test_std_duration</td><td>4.92467</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">CartPole-v1_DDQN_DDQN_High_LR_High_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tbqxirn3' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tbqxirn3</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_120433-tbqxirn3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Run 4/4: DDQN_Low_LR_Low_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_121158-an3rtjf1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/an3rtjf1' target=\"_blank\">CartPole-v1_DDQN_DDQN_Low_LR_Low_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/an3rtjf1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/an3rtjf1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for: CartPole-v1_DDQN_DDQN_Low_LR_Low_Mem ---\n",
            "Episode 0/500 | Duration: 26 | Epsilon: 0.8894\n",
            "Episode 100/500 | Duration: 28 | Epsilon: 0.3845\n",
            "Episode 200/500 | Duration: 163 | Epsilon: 0.1440\n",
            "Episode 300/500 | Duration: 202 | Epsilon: 0.0500\n",
            "Episode 400/500 | Duration: 500 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 243.53 +/- 30.54\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/CartPole-v1_DDQN_DDQN_Low_LR_Low_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to ./videos/CartPole-v1_DDQN_DDQN_Low_LR_Low_Mem\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▂▂▃▃▄▄▄▅▅▆▅▆▇▇▆█▂▁▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▃▂▁▁▁</td></tr><tr><td>duration</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▄▄▃▄▄▃▄▄▄▄▅█▄██████▂█</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>epsilon</td><td>█▇▇▆▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.03775</td></tr><tr><td>duration</td><td>208</td></tr><tr><td>episode</td><td>499</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>243.53</td></tr><tr><td>test_std_duration</td><td>30.53963</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">CartPole-v1_DDQN_DDQN_Low_LR_Low_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/an3rtjf1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/an3rtjf1</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_121158-an3rtjf1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=========================================\n",
            "    STARTING EXPERIMENTS FOR: Acrobot-v1 \n",
            "=========================================\n",
            "\n",
            "\n",
            "--- Starting Run 1/4: DQN_High_LR_High_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_121800-mh45l3ic</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/mh45l3ic' target=\"_blank\">Acrobot-v1_DQN_DQN_High_LR_High_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/mh45l3ic' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/mh45l3ic</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for: Acrobot-v1_DQN_DQN_High_LR_High_Mem ---\n",
            "Episode 0/2000 | Duration: 500 | Epsilon: 0.5661\n",
            "Episode 100/2000 | Duration: 71 | Epsilon: 0.0500\n",
            "Episode 200/2000 | Duration: 97 | Epsilon: 0.0500\n",
            "Episode 300/2000 | Duration: 109 | Epsilon: 0.0500\n",
            "Episode 400/2000 | Duration: 84 | Epsilon: 0.0500\n",
            "Episode 500/2000 | Duration: 84 | Epsilon: 0.0500\n",
            "Episode 600/2000 | Duration: 88 | Epsilon: 0.0500\n",
            "Episode 700/2000 | Duration: 89 | Epsilon: 0.0500\n",
            "Episode 800/2000 | Duration: 94 | Epsilon: 0.0500\n",
            "Episode 900/2000 | Duration: 100 | Epsilon: 0.0500\n",
            "Episode 1000/2000 | Duration: 87 | Epsilon: 0.0500\n",
            "Episode 1100/2000 | Duration: 125 | Epsilon: 0.0500\n",
            "Episode 1200/2000 | Duration: 86 | Epsilon: 0.0500\n",
            "Episode 1300/2000 | Duration: 89 | Epsilon: 0.0500\n",
            "Episode 1400/2000 | Duration: 69 | Epsilon: 0.0500\n",
            "Episode 1500/2000 | Duration: 66 | Epsilon: 0.0500\n",
            "Episode 1600/2000 | Duration: 76 | Epsilon: 0.0500\n",
            "Episode 1700/2000 | Duration: 107 | Epsilon: 0.0500\n",
            "Episode 1800/2000 | Duration: 92 | Epsilon: 0.0500\n",
            "Episode 1900/2000 | Duration: 113 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 69.09 +/- 10.87\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/Acrobot-v1_DQN_DQN_High_LR_High_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to ./videos/Acrobot-v1_DQN_DQN_High_LR_High_Mem\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▁▆▆██▆▆▅▅▅▅▅▆▄▄▄▄▄▃▄▄▄▄▄▅▅▅▅▅▄▄▃▃▄▄▄▄▄▃</td></tr><tr><td>duration</td><td>▄▄▄▂▂▄▄▄▃▃▁▅▅▃▃▃▄▃▆▄▄▅█▂▁▃▂▄▄▅▂▂▆▃▄▇▂▂▇▃</td></tr><tr><td>episode</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>epsilon</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.22421</td></tr><tr><td>duration</td><td>72</td></tr><tr><td>episode</td><td>1999</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>69.09</td></tr><tr><td>test_std_duration</td><td>10.86747</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Acrobot-v1_DQN_DQN_High_LR_High_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/mh45l3ic' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/mh45l3ic</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_121800-mh45l3ic/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Run 2/4: DQN_Low_LR_Low_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_123122-exd68nak</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/exd68nak' target=\"_blank\">Acrobot-v1_DQN_DQN_Low_LR_Low_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/exd68nak' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/exd68nak</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for: Acrobot-v1_DQN_DQN_Low_LR_Low_Mem ---\n",
            "Episode 0/2000 | Duration: 500 | Epsilon: 0.5661\n",
            "Episode 100/2000 | Duration: 500 | Epsilon: 0.0500\n",
            "Episode 200/2000 | Duration: 118 | Epsilon: 0.0500\n",
            "Episode 300/2000 | Duration: 121 | Epsilon: 0.0500\n",
            "Episode 400/2000 | Duration: 96 | Epsilon: 0.0500\n",
            "Episode 500/2000 | Duration: 105 | Epsilon: 0.0500\n",
            "Episode 600/2000 | Duration: 114 | Epsilon: 0.0500\n",
            "Episode 700/2000 | Duration: 86 | Epsilon: 0.0500\n",
            "Episode 800/2000 | Duration: 84 | Epsilon: 0.0500\n",
            "Episode 900/2000 | Duration: 99 | Epsilon: 0.0500\n",
            "Episode 1000/2000 | Duration: 81 | Epsilon: 0.0500\n",
            "Episode 1100/2000 | Duration: 64 | Epsilon: 0.0500\n",
            "Episode 1200/2000 | Duration: 89 | Epsilon: 0.0500\n",
            "Episode 1300/2000 | Duration: 133 | Epsilon: 0.0500\n",
            "Episode 1400/2000 | Duration: 91 | Epsilon: 0.0500\n",
            "Episode 1500/2000 | Duration: 127 | Epsilon: 0.0500\n",
            "Episode 1600/2000 | Duration: 75 | Epsilon: 0.0500\n",
            "Episode 1700/2000 | Duration: 78 | Epsilon: 0.0500\n",
            "Episode 1800/2000 | Duration: 92 | Epsilon: 0.0500\n",
            "Episode 1900/2000 | Duration: 80 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 99.04 +/- 90.47\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/Acrobot-v1_DQN_DQN_Low_LR_Low_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to ./videos/Acrobot-v1_DQN_DQN_Low_LR_Low_Mem\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▁▁▁▁▅▇▆▆▇▆▇█▆▆▆▇▅▅▆▆▆▅▅▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃</td></tr><tr><td>duration</td><td>███▂▂▂▂▂▁▂▁▁▁▁▁▂▁▂▁▁▂▂▁▂▄▁▂▁▁▁▁▂▂▂▁▁▁▁▁▁</td></tr><tr><td>episode</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>epsilon</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.27119</td></tr><tr><td>duration</td><td>88</td></tr><tr><td>episode</td><td>1999</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>99.04</td></tr><tr><td>test_std_duration</td><td>90.46512</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Acrobot-v1_DQN_DQN_Low_LR_Low_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/exd68nak' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/exd68nak</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_123122-exd68nak/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Run 3/4: DDQN_High_LR_High_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_124503-bt5ijr6q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/bt5ijr6q' target=\"_blank\">Acrobot-v1_DDQN_DDQN_High_LR_High_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/bt5ijr6q' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/bt5ijr6q</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for: Acrobot-v1_DDQN_DDQN_High_LR_High_Mem ---\n",
            "Episode 0/2000 | Duration: 500 | Epsilon: 0.5661\n",
            "Episode 100/2000 | Duration: 121 | Epsilon: 0.0500\n",
            "Episode 200/2000 | Duration: 79 | Epsilon: 0.0500\n",
            "Episode 300/2000 | Duration: 83 | Epsilon: 0.0500\n",
            "Episode 400/2000 | Duration: 113 | Epsilon: 0.0500\n",
            "Episode 500/2000 | Duration: 116 | Epsilon: 0.0500\n",
            "Episode 600/2000 | Duration: 71 | Epsilon: 0.0500\n",
            "Episode 700/2000 | Duration: 75 | Epsilon: 0.0500\n",
            "Episode 800/2000 | Duration: 99 | Epsilon: 0.0500\n",
            "Episode 900/2000 | Duration: 88 | Epsilon: 0.0500\n",
            "Episode 1000/2000 | Duration: 63 | Epsilon: 0.0500\n",
            "Episode 1100/2000 | Duration: 105 | Epsilon: 0.0500\n",
            "Episode 1200/2000 | Duration: 105 | Epsilon: 0.0500\n",
            "Episode 1300/2000 | Duration: 97 | Epsilon: 0.0500\n",
            "Episode 1400/2000 | Duration: 103 | Epsilon: 0.0500\n",
            "Episode 1500/2000 | Duration: 63 | Epsilon: 0.0500\n",
            "Episode 1600/2000 | Duration: 78 | Epsilon: 0.0500\n",
            "Episode 1700/2000 | Duration: 98 | Epsilon: 0.0500\n",
            "Episode 1800/2000 | Duration: 73 | Epsilon: 0.0500\n",
            "Episode 1900/2000 | Duration: 80 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 73.39 +/- 11.89\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/Acrobot-v1_DDQN_DDQN_High_LR_High_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to ./videos/Acrobot-v1_DDQN_DDQN_High_LR_High_Mem\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▇█▇▅▅▅▅▅▅▅▅▆▅▆▅▆▆▆▅▆▆▅▆▆▆▆▆▇▆▆▆▆▆▆▆▆▅▆▅</td></tr><tr><td>duration</td><td>█▁▁▁▁▁▁▂▂▂▁▁▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁</td></tr><tr><td>episode</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>epsilon</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.26219</td></tr><tr><td>duration</td><td>63</td></tr><tr><td>episode</td><td>1999</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>73.39</td></tr><tr><td>test_std_duration</td><td>11.89193</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Acrobot-v1_DDQN_DDQN_High_LR_High_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/bt5ijr6q' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/bt5ijr6q</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_124503-bt5ijr6q/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Run 4/4: DDQN_Low_LR_Low_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_125938-tkueyynt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tkueyynt' target=\"_blank\">Acrobot-v1_DDQN_DDQN_Low_LR_Low_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tkueyynt' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tkueyynt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for: Acrobot-v1_DDQN_DDQN_Low_LR_Low_Mem ---\n",
            "Episode 0/2000 | Duration: 500 | Epsilon: 0.7123\n",
            "Episode 100/2000 | Duration: 414 | Epsilon: 0.0500\n",
            "Episode 200/2000 | Duration: 178 | Epsilon: 0.0500\n",
            "Episode 300/2000 | Duration: 244 | Epsilon: 0.0500\n",
            "Episode 400/2000 | Duration: 235 | Epsilon: 0.0500\n",
            "Episode 500/2000 | Duration: 164 | Epsilon: 0.0500\n",
            "Episode 600/2000 | Duration: 180 | Epsilon: 0.0500\n",
            "Episode 700/2000 | Duration: 136 | Epsilon: 0.0500\n",
            "Episode 800/2000 | Duration: 96 | Epsilon: 0.0500\n",
            "Episode 900/2000 | Duration: 107 | Epsilon: 0.0500\n",
            "Episode 1000/2000 | Duration: 109 | Epsilon: 0.0500\n",
            "Episode 1100/2000 | Duration: 94 | Epsilon: 0.0500\n",
            "Episode 1200/2000 | Duration: 109 | Epsilon: 0.0500\n",
            "Episode 1300/2000 | Duration: 160 | Epsilon: 0.0500\n",
            "Episode 1400/2000 | Duration: 121 | Epsilon: 0.0500\n",
            "Episode 1500/2000 | Duration: 102 | Epsilon: 0.0500\n",
            "Episode 1600/2000 | Duration: 103 | Epsilon: 0.0500\n",
            "Episode 1700/2000 | Duration: 114 | Epsilon: 0.0500\n",
            "Episode 1800/2000 | Duration: 102 | Epsilon: 0.0500\n",
            "Episode 1900/2000 | Duration: 87 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 115.43 +/- 82.00\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/Acrobot-v1_DDQN_DDQN_Low_LR_Low_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to ./videos/Acrobot-v1_DDQN_DDQN_Low_LR_Low_Mem\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▃▃▁▅▄▆▄▄▄▆█▆▅▆▅▅▅▆▅▆▆▄▆▅▇▆▆▇▆▄▇▆▅▇▆▆▇▇▆</td></tr><tr><td>duration</td><td>█▄█▆▄▂▂▁▂▂▁▂▂▁▃▂▄▂▃▂▁▁▂▂▁▁▂▁▂▁▁▂▂▂▁▁▃▂▁▂</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epsilon</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.08371</td></tr><tr><td>duration</td><td>86</td></tr><tr><td>episode</td><td>1999</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>115.43</td></tr><tr><td>test_std_duration</td><td>82.00027</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Acrobot-v1_DDQN_DDQN_Low_LR_Low_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tkueyynt' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/tkueyynt</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_125938-tkueyynt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=========================================\n",
            "    STARTING EXPERIMENTS FOR: MountainCar-v0 \n",
            "=========================================\n",
            "\n",
            "\n",
            "--- Starting Run 1/4: DQN_High_LR_High_Mem ---\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_131849-li587cia</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/li587cia' target=\"_blank\">MountainCar-v0_DQN_DQN_High_LR_High_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/li587cia' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/li587cia</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Training for: MountainCar-v0_DQN_DQN_High_LR_High_Mem ---\n",
            "Episode 0/2000 | Duration: 200 | Epsilon: 0.7466\n",
            "Episode 100/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 200/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 300/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 400/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 500/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 600/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 700/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 800/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 900/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1000/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1100/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1200/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1300/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1400/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1500/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1600/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1700/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1800/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1900/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 200.00 +/- 0.00\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/MountainCar-v0_DQN_DQN_High_LR_High_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video saved to ./videos/MountainCar-v0_DQN_DQN_High_LR_High_Mem\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▂▃▃▁▂▄▃▃▅▁▅▁▄▅▃▄▃▄▄▄▃▅▃▃▄▁▄▁█▄▃▄▄▄▂▅▆▄▄▃</td></tr><tr><td>duration</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>epsilon</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.00037</td></tr><tr><td>duration</td><td>200</td></tr><tr><td>episode</td><td>1999</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>200</td></tr><tr><td>test_std_duration</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">MountainCar-v0_DQN_DQN_High_LR_High_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/li587cia' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/li587cia</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_131849-li587cia/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Run 2/4: DQN_Low_LR_Low_Mem ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_134703-lln2htyi</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/lln2htyi' target=\"_blank\">MountainCar-v0_DQN_DQN_Low_LR_Low_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/lln2htyi' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/lln2htyi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Training for: MountainCar-v0_DQN_DQN_Low_LR_Low_Mem ---\n",
            "Episode 0/2000 | Duration: 200 | Epsilon: 0.7466\n",
            "Episode 100/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 200/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 300/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Run MountainCar-v0_DQN_DQN_Low_LR_Low_Mem failed: 'TimeLimit' object has no attribute 'goal_position'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▁▁▂▁▂▁▁▁▁▁▁▂▃▂▂▂▃▂▂▁▁▁▁▂▂▂▂▂▂▃▁▁█▆▄▂▂▃█</td></tr><tr><td>duration</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>epsilon</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.00102</td></tr><tr><td>duration</td><td>200</td></tr><tr><td>episode</td><td>326</td></tr><tr><td>epsilon</td><td>0.05</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">MountainCar-v0_DQN_DQN_Low_LR_Low_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/lln2htyi' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/lln2htyi</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_134703-lln2htyi/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Run 3/4: DDQN_High_LR_High_Mem ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_135039-6j0uy4qr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/6j0uy4qr' target=\"_blank\">MountainCar-v0_DDQN_DDQN_High_LR_High_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/6j0uy4qr' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/6j0uy4qr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Training for: MountainCar-v0_DDQN_DDQN_High_LR_High_Mem ---\n",
            "Episode 0/2000 | Duration: 200 | Epsilon: 0.7466\n",
            "Episode 100/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 200/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 300/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 400/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 500/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 600/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 700/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 800/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 900/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1000/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1100/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1200/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1300/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1400/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1500/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1600/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1700/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1800/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1900/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 200.00 +/- 0.00\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/MountainCar-v0_DDQN_DDQN_High_LR_High_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video saved to ./videos/MountainCar-v0_DDQN_DDQN_High_LR_High_Mem\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▅▂▄▄▄▅▃▄▆▅▅▃▂▆▆▄▅▄▁▆▂█▅▅▃▆▃▆▃▅▁▅▄▄▆▄▄▄▄▄</td></tr><tr><td>duration</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>epsilon</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.00039</td></tr><tr><td>duration</td><td>200</td></tr><tr><td>episode</td><td>1999</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>200</td></tr><tr><td>test_std_duration</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">MountainCar-v0_DDQN_DDQN_High_LR_High_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/6j0uy4qr' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/6j0uy4qr</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_135039-6j0uy4qr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Run 4/4: DDQN_Low_LR_Low_Mem ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_142213-t2h7hhsh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/t2h7hhsh' target=\"_blank\">MountainCar-v0_DDQN_DDQN_Low_LR_Low_Mem</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/t2h7hhsh' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/t2h7hhsh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Training for: MountainCar-v0_DDQN_DDQN_Low_LR_Low_Mem ---\n",
            "Episode 0/2000 | Duration: 200 | Epsilon: 0.8195\n",
            "Episode 100/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 200/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 300/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 400/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 500/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 600/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 700/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 800/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 900/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1000/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1100/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1200/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1300/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1400/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1500/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1600/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1700/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1800/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "Episode 1900/2000 | Duration: 200 | Epsilon: 0.0500\n",
            "--- Training Complete ---\n",
            "--- Running 100 Test Episodes ---\n",
            "Test Results: Avg Duration = 200.00 +/- 0.00\n",
            "--- Recording Video ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos/MountainCar-v0_DDQN_DDQN_Low_LR_Low_Mem folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video saved to ./videos/MountainCar-v0_DDQN_DDQN_Low_LR_Low_Mem\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>█▃▃▄▇▅▂▇▁▃▂▁▁▄▂▁▂▇▁▁▂▂▂▅▂▂▂▁▁▁▂▁▁▂▁▁▁▁▁▃</td></tr><tr><td>duration</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇█████</td></tr><tr><td>epsilon</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_avg_duration</td><td>▁</td></tr><tr><td>test_std_duration</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.0</td></tr><tr><td>duration</td><td>200</td></tr><tr><td>episode</td><td>1999</td></tr><tr><td>epsilon</td><td>0.05</td></tr><tr><td>test_avg_duration</td><td>200</td></tr><tr><td>test_std_duration</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">MountainCar-v0_DDQN_DDQN_Low_LR_Low_Mem</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/t2h7hhsh' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1/runs/t2h7hhsh</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/Assignment1_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_142213-t2h7hhsh/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- All experiments complete. Check Weights & Biases dashboard! ---\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque, namedtuple\n",
        "import math\n",
        "import time\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# Use CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- 1. Replay Memory ---\n",
        "# A named tuple to store individual transitions\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward', 'done'))\n",
        "\n",
        "class ReplayMemory(object):\n",
        "    \"\"\"A simple replay buffer.\"\"\"\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition.\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Sample a batch of transitions.\"\"\"\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "# --- 2. Q-Network Model ---\n",
        "class QNetwork(nn.Module):\n",
        "    \"\"\"Simple MLP network for Q-value approximation.\"\"\"\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)\n",
        "\n",
        "# --- 3. DQN Agent ---\n",
        "class DQNAgent:\n",
        "    \"\"\"\n",
        "    Main agent class to handle training, testing, and logging.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.env_name = config[\"env_name\"]\n",
        "\n",
        "        # Create environment\n",
        "        self.env = gym.make(self.env_name)\n",
        "        n_observations = self.env.observation_space.shape[0]\n",
        "        n_actions = self.env.action_space.n\n",
        "\n",
        "        # Get max steps from environment spec\n",
        "        self.max_episode_steps = self.env.spec.max_episode_steps\n",
        "\n",
        "        # Initialize W&B\n",
        "        self.run = wandb.init(\n",
        "            project=f\"Assignment1_v1\",\n",
        "            config=config,\n",
        "            group=config[\"run_group\"],\n",
        "            name=config[\"run_name\"],\n",
        "            reinit=True\n",
        "        )\n",
        "\n",
        "        # Initialize networks\n",
        "        self.policy_net = QNetwork(n_observations, n_actions).to(device)\n",
        "        self.target_net = QNetwork(n_observations, n_actions).to(device)\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.target_net.eval()  # Target network is only for evaluation\n",
        "\n",
        "        self.optimizer = optim.Adam(\n",
        "            self.policy_net.parameters(),\n",
        "            lr=self.config[\"learning_rate\"]\n",
        "        )\n",
        "        self.memory = ReplayMemory(self.config[\"memory_size\"])\n",
        "        self.criterion = nn.SmoothL1Loss() # Huber Loss\n",
        "\n",
        "        self.steps_done = 0\n",
        "\n",
        "    def select_action(self, state, epsilon):\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        if random.random() > epsilon:\n",
        "            with torch.no_grad():\n",
        "                return self.policy_net(state).max(1)[1].view(1, 1)\n",
        "        else:\n",
        "            return torch.tensor(\n",
        "                [[self.env.action_space.sample()]],\n",
        "                device=device, dtype=torch.long\n",
        "            )\n",
        "\n",
        "    def optimize_model(self):\n",
        "        \"\"\"Performs one optimization step on the policy network.\"\"\"\n",
        "        if len(self.memory) < self.config[\"batch_size\"]:\n",
        "            return None  # Not enough memory to sample\n",
        "\n",
        "        transitions = self.memory.sample(self.config[\"batch_size\"])\n",
        "        batch = Transition(*zip(*transitions))\n",
        "\n",
        "        state_batch = torch.cat(batch.state)\n",
        "        action_batch = torch.cat(batch.action)\n",
        "        reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "        non_final_mask = torch.tensor(\n",
        "            tuple(s is not None for s in batch.next_state),\n",
        "            device=device, dtype=torch.bool\n",
        "        )\n",
        "        next_state_batch = torch.cat(\n",
        "            [s for s in batch.next_state if s is not None]\n",
        "        )\n",
        "\n",
        "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "        next_state_values = torch.zeros(self.config[\"batch_size\"], device=device)\n",
        "\n",
        "        if self.config[\"use_ddqn\"]:\n",
        "            # --- DDQN ---\n",
        "            best_next_actions = self.policy_net(next_state_batch).max(1)[1].unsqueeze(1)\n",
        "            next_state_values[non_final_mask] = self.target_net(\n",
        "                next_state_batch\n",
        "            ).gather(1, best_next_actions).squeeze(1).detach()\n",
        "        else:\n",
        "            # --- Standard DQN ---\n",
        "            next_state_values[non_final_mask] = self.target_net(\n",
        "                next_state_batch\n",
        "            ).max(1)[0].detach()\n",
        "\n",
        "        expected_state_action_values = (\n",
        "            next_state_values * self.config[\"gamma\"]\n",
        "        ) + reward_batch\n",
        "\n",
        "        loss = self.criterion(\n",
        "            state_action_values,\n",
        "            expected_state_action_values.unsqueeze(1)\n",
        "        )\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train_agent(self):\n",
        "        \"\"\"Main training loop.\"\"\"\n",
        "        print(f\"--- Starting Training for: {self.config['run_name']} ---\")\n",
        "        num_episodes = self.config[\"num_episodes\"]\n",
        "\n",
        "        for i_episode in range(num_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "            episode_loss = 0\n",
        "            episode_duration = 0\n",
        "\n",
        "            for t in range(self.max_episode_steps):\n",
        "                epsilon = self.config[\"eps_end\"] + (\n",
        "                    self.config[\"eps_start\"] - self.config[\"eps_end\"]\n",
        "                ) * math.exp(-1. * self.steps_done / self.config[\"eps_decay\"])\n",
        "\n",
        "                self.steps_done += 1\n",
        "\n",
        "                action = self.select_action(state, epsilon)\n",
        "                observation, reward, terminated, truncated, _ = self.env.step(action.item())\n",
        "                done = terminated or truncated\n",
        "\n",
        "                reward = torch.tensor([reward], device=device)\n",
        "\n",
        "                if terminated:\n",
        "                    next_state = None\n",
        "                else:\n",
        "                    next_state = torch.tensor(\n",
        "                        observation, dtype=torch.float32, device=device\n",
        "                    ).unsqueeze(0)\n",
        "\n",
        "                self.memory.push(state, action, next_state, reward, done)\n",
        "                state = next_state\n",
        "                loss = self.optimize_model()\n",
        "\n",
        "                if loss:\n",
        "                    episode_loss += loss\n",
        "\n",
        "                # Soft update\n",
        "                target_net_state_dict = self.target_net.state_dict()\n",
        "                policy_net_state_dict = self.policy_net.state_dict()\n",
        "                tau = self.config[\"tau\"]\n",
        "                for key in policy_net_state_dict:\n",
        "                    target_net_state_dict[key] = policy_net_state_dict[key]*tau + target_net_state_dict[key]*(1-tau)\n",
        "                self.target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "                episode_duration += 1\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            # Log to W&B\n",
        "            self.run.log({\n",
        "                \"episode\": i_episode,\n",
        "                \"duration\": episode_duration,\n",
        "                \"epsilon\": epsilon,\n",
        "                \"avg_loss\": episode_loss / episode_duration if episode_duration > 0 else 0\n",
        "            })\n",
        "\n",
        "            if i_episode % 100 == 0:\n",
        "                print(f\"Episode {i_episode}/{num_episodes} | Duration: {episode_duration} | Epsilon: {epsilon:.4f}\")\n",
        "\n",
        "        print(\"--- Training Complete ---\")\n",
        "\n",
        "    def test_agent(self, num_tests=100):\n",
        "        \"\"\"Test the trained agent for 100 episodes.\"\"\"\n",
        "        print(f\"--- Running {num_tests} Test Episodes ---\")\n",
        "        test_env = gym.make(self.env_name)\n",
        "        test_durations = []\n",
        "\n",
        "        for _ in range(num_tests):\n",
        "            state, _ = test_env.reset()\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "            terminated = False\n",
        "            truncated = False\n",
        "            duration = 0\n",
        "\n",
        "            while not (terminated or truncated):\n",
        "                with torch.no_grad():\n",
        "                    action = self.policy_net(state).max(1)[1].view(1, 1)\n",
        "\n",
        "                observation, _, terminated, truncated, _ = test_env.step(action.item())\n",
        "                state = torch.tensor(\n",
        "                    observation, dtype=torch.float32, device=device\n",
        "                ).unsqueeze(0)\n",
        "                duration += 1\n",
        "            test_durations.append(duration)\n",
        "\n",
        "        test_env.close()\n",
        "\n",
        "        avg_duration = np.mean(test_durations)\n",
        "        std_duration = np.std(test_durations)\n",
        "\n",
        "        print(f\"Test Results: Avg Duration = {avg_duration:.2f} +/- {std_duration:.2f}\")\n",
        "        self.run.log({\n",
        "            \"test_avg_duration\": avg_duration,\n",
        "            \"test_std_duration\": std_duration,\n",
        "            \"test_durations\": wandb.Histogram(test_durations)\n",
        "        })\n",
        "\n",
        "    def record_video(self):\n",
        "        \"\"\"Record a video of the agent acting in the environment.\"\"\"\n",
        "        print(\"--- Recording Video ---\")\n",
        "        video_dir = f\"./videos/{self.config['run_name']}\"\n",
        "\n",
        "        if not os.path.exists(video_dir):\n",
        "            os.makedirs(video_dir)\n",
        "\n",
        "        video_env = gym.make(self.env_name, render_mode=\"rgb_array\")\n",
        "        video_env = gym.wrappers.RecordVideo(\n",
        "            video_env,\n",
        "            video_folder=video_dir,\n",
        "            name_prefix=f\"{self.config['run_name']}-agent\"\n",
        "        )\n",
        "\n",
        "        state, _ = video_env.reset()\n",
        "        state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "\n",
        "        while not (terminated or truncated):\n",
        "            with torch.no_grad():\n",
        "                action = self.policy_net(state).max(1)[1].view(1, 1)\n",
        "\n",
        "            observation, _, terminated, truncated, _ = video_env.step(action.item())\n",
        "            state = torch.tensor(\n",
        "                observation, dtype=torch.float32, device=device\n",
        "            ).unsqueeze(0)\n",
        "\n",
        "        video_env.close()\n",
        "        print(f\"Video saved to {video_dir}\")\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Close the environment and W&B run.\"\"\"\n",
        "        self.env.close()\n",
        "        self.run.finish()\n",
        "\n",
        "# --- 4. Main Execution and Hyperparameter Search ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Environments to run\n",
        "    # Pendulum-v1 is EXCLUDED as it requires a different algorithm\n",
        "    compatible_environments = [\"CartPole-v1\", \"Acrobot-v1\"]\n",
        "\n",
        "    # Define the hyperparameter search space\n",
        "    search_space = [\n",
        "        {\n",
        "            \"config_name\": \"DQN_High_LR_High_Mem\",\n",
        "            \"use_ddqn\": False,\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"memory_size\": 10000,\n",
        "            \"batch_size\": 128,\n",
        "            \"gamma\": 0.99,\n",
        "            \"eps_decay\": 1000,\n",
        "        },\n",
        "        {\n",
        "            \"config_name\": \"DQN_Low_LR_Low_Mem\",\n",
        "            \"use_ddqn\": False,\n",
        "            \"learning_rate\": 0.0001,\n",
        "            \"memory_size\": 2000,\n",
        "            \"batch_size\": 32,\n",
        "            \"gamma\": 0.99,\n",
        "            \"eps_decay\": 1000,\n",
        "        },\n",
        "        {\n",
        "            \"config_name\": \"DDQN_High_LR_High_Mem\",\n",
        "            \"use_ddqn\": True,\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"memory_size\": 10000,\n",
        "            \"batch_size\": 128,\n",
        "            \"gamma\": 0.99,\n",
        "            \"eps_decay\": 1000,\n",
        "        },\n",
        "        {\n",
        "            \"config_name\": \"DDQN_Low_LR_Low_Mem\",\n",
        "            \"use_ddqn\": True,\n",
        "            \"learning_rate\": 0.0001,\n",
        "            \"memory_size\": 2000,\n",
        "            \"batch_size\": 32,\n",
        "            \"gamma\": 0.95,\n",
        "            \"eps_decay\": 2000,\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # Common parameters for all runs\n",
        "    common_params = {\n",
        "        \"eps_start\": 0.9,\n",
        "        \"eps_end\": 0.05,\n",
        "        \"target_update_mode\": \"soft\",\n",
        "        \"tau\": 0.005,\n",
        "    }\n",
        "\n",
        "    # --- Run the Search for each Environment ---\n",
        "    for env_name in compatible_environments:\n",
        "        print(f\"\\n=========================================\")\n",
        "        print(f\"    STARTING EXPERIMENTS FOR: {env_name} \")\n",
        "        print(f\"=========================================\\n\")\n",
        "\n",
        "        # Adjust training length based on environment difficulty\n",
        "        if \"Acrobot\" in env_name:\n",
        "            num_episodes = 2000\n",
        "        else:\n",
        "            num_episodes = 500\n",
        "\n",
        "        for i, specific_config in enumerate(search_space):\n",
        "            print(f\"\\n--- Starting Run {i+1}/{len(search_space)}: {specific_config['config_name']} ---\")\n",
        "\n",
        "            config = {**common_params, **specific_config}\n",
        "            config[\"env_name\"] = env_name\n",
        "            config[\"num_episodes\"] = num_episodes\n",
        "\n",
        "            # Create unique W&B names\n",
        "            model_type = \"DDQN\" if config[\"use_ddqn\"] else \"DQN\"\n",
        "            config[\"run_name\"] = f\"{env_name}_{model_type}_{specific_config['config_name']}\"\n",
        "            config[\"run_group\"] = f\"Group_{env_name}\"\n",
        "\n",
        "            try:\n",
        "                agent = DQNAgent(config)\n",
        "                agent.train_agent()\n",
        "                agent.test_agent(num_tests=100)\n",
        "                agent.record_video()\n",
        "            except Exception as e:\n",
        "                print(f\"Run {config['run_name']} failed: {e}\")\n",
        "            finally:\n",
        "                if 'agent' in locals():\n",
        "                    agent.close()\n",
        "                time.sleep(5)\n",
        "\n",
        "    print(\"--- All experiments complete. Check Weights & Biases dashboard! ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pendoluim"
      ],
      "metadata": {
        "id": "mD5_p7pflrzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import math\n",
        "from collections import deque, namedtuple\n",
        "import time\n",
        "import wandb\n",
        "\n",
        "# Ensure the environment can be rendered (for video recording)\n",
        "import os\n",
        "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = '1'\n",
        "\n",
        "\n",
        "#################################################\n",
        "#  1. Discretization Wrapper\n",
        "#################################################\n",
        "\n",
        "class DiscretizeActionWrapper(gym.ActionWrapper):\n",
        "    \"\"\"\n",
        "    Wraps the Pendulum-v1 environment to discretize the continuous action space.\n",
        "    \"\"\"\n",
        "    def __init__(self, env, n_actions):\n",
        "        super().__init__(env)\n",
        "        self.n_actions = n_actions\n",
        "        # Create a discrete action space\n",
        "        self.action_space = gym.spaces.Discrete(n_actions)\n",
        "        # Map discrete actions (0, 1, ..., n_actions-1) to continuous values\n",
        "        self.continuous_actions = np.linspace(\n",
        "            env.action_space.low[0],\n",
        "            env.action_space.high[0],\n",
        "            n_actions\n",
        "        )\n",
        "\n",
        "    def action(self, action):\n",
        "        # Map the discrete action index back to a continuous torque value\n",
        "        return [self.continuous_actions[action]]\n",
        "\n",
        "#################################################\n",
        "#  2. Replay Buffer\n",
        "#################################################\n",
        "\n",
        "# Use namedtuple for a more readable transition structure\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'reward', 'next_state', 'done'))\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"A fixed-size buffer to store experience tuples.\"\"\"\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition.\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Randomly sample a batch of transitions.\"\"\"\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "#################################################\n",
        "#  3. Q-Network (MLP Model)\n",
        "#################################################\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    \"\"\"MLP model for Q-value approximation.\"\"\"\n",
        "    def __init__(self, state_dim, n_actions):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(state_dim, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)\n",
        "\n",
        "#################################################\n",
        "#  4. DQN/DDQN Agent\n",
        "#################################################\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_dim, n_actions, config, use_ddqn=False):\n",
        "        self.state_dim = state_dim\n",
        "        self.n_actions = n_actions\n",
        "        self.config = config\n",
        "        self.use_ddqn = use_ddqn\n",
        "\n",
        "        self.gamma = config['gamma']\n",
        "        self.epsilon_start = 1.0\n",
        "        self.epsilon_end = 0.01\n",
        "        self.epsilon_decay = config['epsilon_decay']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.target_update_freq = 100 # Update target net every 100 learning steps\n",
        "        self.steps_done = 0\n",
        "\n",
        "        # Use GPU if available\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Initialize policy and target networks\n",
        "        self.policy_net = QNetwork(state_dim, n_actions).to(self.device)\n",
        "        self.target_net = QNetwork(state_dim, n_actions).to(self.device)\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.target_net.eval()  # Target network is only for evaluation\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)\n",
        "\n",
        "        # *** Create memory with the capacity from config ***\n",
        "        self.memory = ReplayBuffer(config['memory_size'])\n",
        "\n",
        "        # Log model architecture to W&B\n",
        "        if wandb.run:\n",
        "             wandb.watch(self.policy_net)\n",
        "\n",
        "    def select_action(self, state, exploration=True):\n",
        "        \"\"\"Selects an action using an epsilon-greedy policy.\"\"\"\n",
        "        # Calculate current epsilon\n",
        "        if exploration:\n",
        "            epsilon = self.epsilon_end + (self.epsilon_start - self.epsilon_end) * \\\n",
        "                      math.exp(-1. * self.steps_done / self.epsilon_decay)\n",
        "            self.steps_done += 1\n",
        "        else:\n",
        "            epsilon = 0.0 # No exploration for testing\n",
        "\n",
        "        # Epsilon-greedy selection\n",
        "        if random.random() > epsilon:\n",
        "            with torch.no_grad():\n",
        "                state = torch.tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "                return self.policy_net(state).max(1)[1].view(1, 1)\n",
        "        else:\n",
        "            return torch.tensor([[random.randrange(self.n_actions)]], device=self.device, dtype=torch.long)\n",
        "\n",
        "    def optimize_model(self):\n",
        "        \"\"\"Performs one step of optimization on the policy network.\"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return None  # Not enough samples in memory\n",
        "\n",
        "        transitions = self.memory.sample(self.batch_size)\n",
        "        batch = Transition(*zip(*transitions))\n",
        "\n",
        "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                              batch.next_state)), device=self.device, dtype=torch.bool)\n",
        "\n",
        "        non_final_next_states = torch.cat([torch.tensor(s, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "                                           for s in batch.next_state if s is not None])\n",
        "\n",
        "        state_batch = torch.cat([torch.tensor(s, dtype=torch.float32, device=self.device).unsqueeze(0) for s in batch.state])\n",
        "        action_batch = torch.cat(batch.action)\n",
        "        reward_batch = torch.cat([torch.tensor([r], dtype=torch.float32, device=self.device) for r in batch.reward])\n",
        "\n",
        "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "        next_state_values = torch.zeros(self.batch_size, device=self.device)\n",
        "\n",
        "        if self.use_ddqn:\n",
        "            # --- DDQN ---\n",
        "            best_actions = self.policy_net(non_final_next_states).max(1)[1].unsqueeze(1)\n",
        "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).gather(1, best_actions).squeeze()\n",
        "        else:\n",
        "            # --- Standard DQN ---\n",
        "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1)[0].detach()\n",
        "\n",
        "        expected_state_action_values = (next_state_values * self.gamma) + reward_batch\n",
        "\n",
        "        loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        for param in self.policy_net.parameters():\n",
        "            param.grad.data.clamp_(-1, 1) # Gradient clipping\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def update_target_net(self):\n",
        "        \"\"\"Hard update of the target network's weights.\"\"\"\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.policy_net.state_dict(), path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.policy_net.load_state_dict(torch.load(path))\n",
        "        self.target_net.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "#################################################\n",
        "#  5. Training and Evaluation Function\n",
        "#################################################\n",
        "\n",
        "def train_and_evaluate(config):\n",
        "    \"\"\"\n",
        "    Main function to train and evaluate an agent based on a config dictionary.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize W&B\n",
        "    run = wandb.init(\n",
        "        project=\"DQN_DDQN_Pendulum\",\n",
        "        config=config,\n",
        "        reinit=True # Allows multiple runs in the same script\n",
        "    )\n",
        "\n",
        "    # Create environment\n",
        "    base_env = gym.make(\"Pendulum-v1\")\n",
        "    env = DiscretizeActionWrapper(base_env, n_actions=config['n_actions'])\n",
        "\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    n_actions = env.action_space.n\n",
        "\n",
        "    agent = DQNAgent(\n",
        "        state_dim,\n",
        "        n_actions,\n",
        "        config,\n",
        "        use_ddqn=config['use_ddqn']\n",
        "    )\n",
        "\n",
        "    print(f\"--- Starting Run: {run.name} ---\")\n",
        "    print(f\"Config: {config}\")\n",
        "\n",
        "    total_learn_steps = 0\n",
        "\n",
        "    # --- Training Phase ---\n",
        "    for i_episode in range(config['num_episodes']):\n",
        "        state, _ = env.reset()\n",
        "        episode_reward = 0\n",
        "        episode_loss = 0\n",
        "        n_steps = 0\n",
        "\n",
        "        for t in range(200): # Pendulum-v1 has a fixed 200-step duration\n",
        "            action = agent.select_action(state, exploration=True)\n",
        "            next_state, reward, terminated, truncated, _ = env.step(action.item())\n",
        "            done = terminated or truncated\n",
        "            episode_reward += reward\n",
        "\n",
        "            agent.memory.push(state, action, reward, next_state if not done else None, done)\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "            loss = agent.optimize_model()\n",
        "            if loss is not None:\n",
        "                episode_loss += loss\n",
        "                n_steps += 1\n",
        "                total_learn_steps += 1\n",
        "\n",
        "            if total_learn_steps % agent.target_update_freq == 0:\n",
        "                agent.update_target_net()\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        avg_loss = (episode_loss / n_steps) if n_steps > 0 else 0\n",
        "        current_epsilon = agent.epsilon_end + (agent.epsilon_start - agent.epsilon_end) * \\\n",
        "                          math.exp(-1. * agent.steps_done / agent.epsilon_decay)\n",
        "\n",
        "        wandb.log({\n",
        "            \"episode\": i_episode,\n",
        "            \"total_reward\": episode_reward,\n",
        "            \"avg_loss\": avg_loss,\n",
        "            \"epsilon\": current_epsilon,\n",
        "            \"steps_done\": agent.steps_done\n",
        "        })\n",
        "\n",
        "        if i_episode % 50 == 0:\n",
        "            print(f\"Episode {i_episode}: Reward = {episode_reward:.2f}, Avg Loss = {avg_loss:.4f}, Epsilon = {current_epsilon:.3f}\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    # --- Testing & Recording Phase ---\n",
        "    print(\"Starting testing and video recording...\")\n",
        "\n",
        "    video_dir = f\"./videos/{run.name}\"\n",
        "    test_env = DiscretizeActionWrapper(\n",
        "        gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\"),\n",
        "        n_actions=config['n_actions']\n",
        "    )\n",
        "    test_env = RecordVideo(test_env, video_dir, episode_trigger=lambda e: e < 3)\n",
        "\n",
        "    test_rewards = []\n",
        "    for i_test in range(100):\n",
        "        state, _ = test_env.reset()\n",
        "        episode_reward = 0\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = agent.select_action(state, exploration=False)\n",
        "            next_state, reward, terminated, truncated, _ = test_env.step(action.item())\n",
        "            done = terminated or truncated\n",
        "            episode_reward += reward\n",
        "            state = next_state\n",
        "        test_rewards.append(episode_reward)\n",
        "\n",
        "    test_env.close()\n",
        "\n",
        "    avg_test_reward = np.mean(test_rewards)\n",
        "    std_test_reward = np.std(test_rewards)\n",
        "\n",
        "    print(f\"Test Results: Avg Reward = {avg_test_reward:.2f} +/- {std_test_reward:.2f}\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"avg_test_reward\": avg_test_reward,\n",
        "        \"std_test_reward\": std_test_reward,\n",
        "        \"video\": wandb.Video(os.path.join(video_dir, \"rl-video-episode-0.mp4\"), fps=4, format=\"mp4\")\n",
        "    })\n",
        "\n",
        "    print(f\"--- Run {run.name} Finished ---\")\n",
        "    run.finish()\n",
        "\n",
        "\n",
        "#################################################\n",
        "#  6. Main Execution\n",
        "#################################################\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define the hyperparameter setups to test\n",
        "    # All configurations now use memory_size = 6000\n",
        "\n",
        "    # Config 1: Standard DQN\n",
        "    config1 = {\n",
        "        \"run_name\": \"DQN_fast_decay\",\n",
        "        \"use_ddqn\": False,\n",
        "        \"num_episodes\": 500,\n",
        "        \"n_actions\": 5,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_decay\": 5000,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"memory_size\": 6000, # <-- UPDATED\n",
        "        \"batch_size\": 64\n",
        "    }\n",
        "\n",
        "    # Config 2: Standard DDQN\n",
        "    config2 = {\n",
        "        \"run_name\": \"DDQN_fast_decay\",\n",
        "        \"use_ddqn\": True,\n",
        "        \"num_episodes\": 500,\n",
        "        \"n_actions\": 5,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_decay\": 5000,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"memory_size\": 6000, # <-- UPDATED\n",
        "        \"batch_size\": 64\n",
        "    }\n",
        "\n",
        "    # Config 3: DDQN with slower decay\n",
        "    config3 = {\n",
        "        \"run_name\": \"DDQN_slow_decay\",\n",
        "        \"use_ddqn\": True,\n",
        "        \"num_episodes\": 500,\n",
        "        \"n_actions\": 5,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_decay\": 20000,\n",
        "        \"learning_rate\": 0.0005,\n",
        "        \"memory_size\": 6000, # <-- UPDATED\n",
        "        \"batch_size\": 128\n",
        "    }\n",
        "\n",
        "    # Config 4: DQN with slower decay\n",
        "    config4 = {\n",
        "        \"run_name\": \"DQN_slow_decay\",\n",
        "        \"use_ddqn\": False,\n",
        "        \"num_episodes\": 500,\n",
        "        \"n_actions\": 5,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_decay\": 20000,\n",
        "        \"learning_rate\": 0.0005,\n",
        "        \"memory_size\": 6000, # <-- UPDATED\n",
        "        \"batch_size\": 128\n",
        "    }\n",
        "\n",
        "    all_configs = [config1, config2, config3, config4]\n",
        "\n",
        "    for cfg in all_configs:\n",
        "        train_and_evaluate(cfg)\n",
        "\n",
        "    print(\"All experiments complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iuYHPaDpZ1Kw",
        "outputId": "926531ae-17d0-46c4-dfbe-d07eff467452"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_190127-ga9300se</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/ga9300se' target=\"_blank\">unique-oath-1</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/ga9300se' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/ga9300se</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Run: unique-oath-1 ---\n",
            "Config: {'run_name': 'DQN_fast_decay', 'use_ddqn': False, 'num_episodes': 500, 'n_actions': 5, 'gamma': 0.99, 'epsilon_decay': 5000, 'learning_rate': 0.001, 'memory_size': 6000, 'batch_size': 64}\n",
            "Episode 0: Reward = -1304.40, Avg Loss = 1.5544, Epsilon = 0.961\n",
            "Episode 50: Reward = -122.15, Avg Loss = 0.9430, Epsilon = 0.139\n",
            "Episode 100: Reward = -127.98, Avg Loss = 0.2349, Epsilon = 0.027\n",
            "Episode 150: Reward = -2.98, Avg Loss = 0.2917, Epsilon = 0.012\n",
            "Episode 200: Reward = -242.20, Avg Loss = 0.2526, Epsilon = 0.010\n",
            "Episode 250: Reward = -121.84, Avg Loss = 0.3145, Epsilon = 0.010\n",
            "Episode 300: Reward = -126.20, Avg Loss = 0.2226, Epsilon = 0.010\n",
            "Episode 350: Reward = -130.32, Avg Loss = 0.2190, Epsilon = 0.010\n",
            "Episode 400: Reward = -122.15, Avg Loss = 0.3693, Epsilon = 0.010\n",
            "Episode 450: Reward = -245.49, Avg Loss = 0.1958, Epsilon = 0.010\n",
            "Training complete.\n",
            "Starting testing and video recording...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: Avg Reward = -136.44 +/- 89.88\n",
            "--- Run unique-oath-1 Finished ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▃██▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>avg_test_reward</td><td>▁</td></tr><tr><td>episode</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇█████</td></tr><tr><td>epsilon</td><td>█▇▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>std_test_reward</td><td>▁</td></tr><tr><td>steps_done</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇████</td></tr><tr><td>total_reward</td><td>▁▆▇▇▇▇▅▇▅▄▇▇▇▇█▇▄▇▇▅▄▅▅██▅▇▇▇▅▇█▅▇▇█▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.24922</td></tr><tr><td>avg_test_reward</td><td>-136.44267</td></tr><tr><td>episode</td><td>499</td></tr><tr><td>epsilon</td><td>0.01</td></tr><tr><td>std_test_reward</td><td>89.87898</td></tr><tr><td>steps_done</td><td>100000</td></tr><tr><td>total_reward</td><td>-120.36094</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">unique-oath-1</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/ga9300se' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/ga9300se</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_190127-ga9300se/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_190612-un74gmhk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/un74gmhk' target=\"_blank\">splendid-oath-2</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/un74gmhk' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/un74gmhk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Run: splendid-oath-2 ---\n",
            "Config: {'run_name': 'DDQN_fast_decay', 'use_ddqn': True, 'num_episodes': 500, 'n_actions': 5, 'gamma': 0.99, 'epsilon_decay': 5000, 'learning_rate': 0.001, 'memory_size': 6000, 'batch_size': 64}\n",
            "Episode 0: Reward = -1700.73, Avg Loss = 2.9056, Epsilon = 0.961\n",
            "Episode 50: Reward = -120.47, Avg Loss = 1.0065, Epsilon = 0.139\n",
            "Episode 100: Reward = -246.38, Avg Loss = 0.2331, Epsilon = 0.027\n",
            "Episode 150: Reward = -15.74, Avg Loss = 0.2742, Epsilon = 0.012\n",
            "Episode 200: Reward = -8.26, Avg Loss = 0.2285, Epsilon = 0.010\n",
            "Episode 250: Reward = -232.17, Avg Loss = 0.2603, Epsilon = 0.010\n",
            "Episode 300: Reward = -132.79, Avg Loss = 0.2541, Epsilon = 0.010\n",
            "Episode 350: Reward = -129.53, Avg Loss = 0.2486, Epsilon = 0.010\n",
            "Episode 400: Reward = -242.29, Avg Loss = 0.1933, Epsilon = 0.010\n",
            "Episode 450: Reward = -5.46, Avg Loss = 0.2798, Epsilon = 0.010\n",
            "Training complete.\n",
            "Starting testing and video recording...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: Avg Reward = -137.01 +/- 86.15\n",
            "--- Run splendid-oath-2 Finished ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>██▃▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>avg_test_reward</td><td>▁</td></tr><tr><td>episode</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>epsilon</td><td>██▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>std_test_reward</td><td>▁</td></tr><tr><td>steps_done</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>total_reward</td><td>▁▇▆▆▇█▇▇█▇▇▇▇█▇▇██▇█▇▇▇█▇▇▇█▇▇▆▇▇▆▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.32766</td></tr><tr><td>avg_test_reward</td><td>-137.01323</td></tr><tr><td>episode</td><td>499</td></tr><tr><td>epsilon</td><td>0.01</td></tr><tr><td>std_test_reward</td><td>86.14521</td></tr><tr><td>steps_done</td><td>100000</td></tr><tr><td>total_reward</td><td>-239.59003</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">splendid-oath-2</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/un74gmhk' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/un74gmhk</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_190612-un74gmhk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_191211-fxbmm3xv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/fxbmm3xv' target=\"_blank\">worthy-snowflake-3</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/fxbmm3xv' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/fxbmm3xv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Run: worthy-snowflake-3 ---\n",
            "Config: {'run_name': 'DDQN_slow_decay', 'use_ddqn': True, 'num_episodes': 500, 'n_actions': 5, 'gamma': 0.99, 'epsilon_decay': 20000, 'learning_rate': 0.0005, 'memory_size': 6000, 'batch_size': 128}\n",
            "Episode 0: Reward = -919.29, Avg Loss = 1.8942, Epsilon = 0.990\n",
            "Episode 50: Reward = -625.31, Avg Loss = 2.7915, Epsilon = 0.604\n",
            "Episode 100: Reward = -253.81, Avg Loss = 1.2355, Epsilon = 0.371\n",
            "Episode 150: Reward = -597.83, Avg Loss = 1.0375, Epsilon = 0.229\n",
            "Episode 200: Reward = -242.47, Avg Loss = 0.6506, Epsilon = 0.143\n",
            "Episode 250: Reward = -128.42, Avg Loss = 0.3756, Epsilon = 0.090\n",
            "Episode 300: Reward = -5.17, Avg Loss = 0.4511, Epsilon = 0.059\n",
            "Episode 350: Reward = -246.33, Avg Loss = 0.2286, Epsilon = 0.040\n",
            "Episode 400: Reward = -10.62, Avg Loss = 0.2865, Epsilon = 0.028\n",
            "Episode 450: Reward = -121.10, Avg Loss = 0.2008, Epsilon = 0.021\n",
            "Training complete.\n",
            "Starting testing and video recording...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: Avg Reward = -147.79 +/- 80.19\n",
            "--- Run worthy-snowflake-3 Finished ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▄▅▅▆██▇▆▆▆▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>avg_test_reward</td><td>▁</td></tr><tr><td>episode</td><td>▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>epsilon</td><td>█▇▅▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>std_test_reward</td><td>▁</td></tr><tr><td>steps_done</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>total_reward</td><td>▃▄▁▃▃▆▅▇▆▅▅▆▇█▆▇▇▇▆▇█▇▇▇▇▆██▇▇▇▆▇▇██▇▇▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.20418</td></tr><tr><td>avg_test_reward</td><td>-147.78772</td></tr><tr><td>episode</td><td>499</td></tr><tr><td>epsilon</td><td>0.01667</td></tr><tr><td>std_test_reward</td><td>80.18873</td></tr><tr><td>steps_done</td><td>100000</td></tr><tr><td>total_reward</td><td>-129.61092</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">worthy-snowflake-3</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/fxbmm3xv' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/fxbmm3xv</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_191211-fxbmm3xv/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_192050-7prnu06q</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/7prnu06q' target=\"_blank\">lilac-shape-4</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/7prnu06q' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/7prnu06q</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Run: lilac-shape-4 ---\n",
            "Config: {'run_name': 'DQN_slow_decay', 'use_ddqn': False, 'num_episodes': 500, 'n_actions': 5, 'gamma': 0.99, 'epsilon_decay': 20000, 'learning_rate': 0.0005, 'memory_size': 6000, 'batch_size': 128}\n",
            "Episode 0: Reward = -1085.51, Avg Loss = 2.2274, Epsilon = 0.990\n",
            "Episode 50: Reward = -623.49, Avg Loss = 2.5838, Epsilon = 0.604\n",
            "Episode 100: Reward = -357.75, Avg Loss = 1.2742, Epsilon = 0.371\n",
            "Episode 150: Reward = -380.91, Avg Loss = 0.8445, Epsilon = 0.229\n",
            "Episode 200: Reward = -250.83, Avg Loss = 0.7239, Epsilon = 0.143\n",
            "Episode 250: Reward = -121.21, Avg Loss = 0.4615, Epsilon = 0.090\n",
            "Episode 300: Reward = -246.68, Avg Loss = 0.2476, Epsilon = 0.059\n",
            "Episode 350: Reward = -119.66, Avg Loss = 0.1587, Epsilon = 0.040\n",
            "Episode 400: Reward = -230.01, Avg Loss = 0.2787, Epsilon = 0.028\n",
            "Episode 450: Reward = -116.77, Avg Loss = 0.1353, Epsilon = 0.021\n",
            "Training complete.\n",
            "Starting testing and video recording...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: Avg Reward = -158.59 +/- 82.32\n",
            "--- Run lilac-shape-4 Finished ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▇███▄▄▄▄▄▄▃▃▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>avg_test_reward</td><td>▁</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>epsilon</td><td>█▇▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>std_test_reward</td><td>▁</td></tr><tr><td>steps_done</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>total_reward</td><td>▁▄▄▃▄▅██▇▇▇▇▇▇▆▇▇█▇█▇▇███████▇▇▇██████▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.17139</td></tr><tr><td>avg_test_reward</td><td>-158.58513</td></tr><tr><td>episode</td><td>499</td></tr><tr><td>epsilon</td><td>0.01667</td></tr><tr><td>std_test_reward</td><td>82.32308</td></tr><tr><td>steps_done</td><td>100000</td></tr><tr><td>total_reward</td><td>-127.1124</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lilac-shape-4</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/7prnu06q' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum/runs/7prnu06q</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_Pendulum</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_192050-7prnu06q/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All experiments complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mountain car"
      ],
      "metadata": {
        "id": "UhPz3rwcl1Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import math\n",
        "from collections import deque, namedtuple\n",
        "import time\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# Ensure the environment can be rendered (for video recording)\n",
        "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = '1'\n",
        "\n",
        "#################################################\n",
        "#  1. Replay Buffer\n",
        "#################################################\n",
        "\n",
        "# Use namedtuple for a more readable transition structure\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'reward', 'next_state', 'done'))\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"A fixed-size buffer to store experience tuples.\"\"\"\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition.\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Randomly sample a batch of transitions.\"\"\"\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "#################################################\n",
        "#  2. Q-Network (MLP Model)\n",
        "#################################################\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    \"\"\"MLP model for Q-value approximation.\"\"\"\n",
        "    def __init__(self, state_dim, n_actions):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(state_dim, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)\n",
        "\n",
        "#################################################\n",
        "#  3. DQN/DDQN Agent\n",
        "#################################################\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_dim, n_actions, config, use_ddqn=False):\n",
        "        self.state_dim = state_dim\n",
        "        self.n_actions = n_actions\n",
        "        self.config = config\n",
        "        self.use_ddqn = use_ddqn\n",
        "\n",
        "        self.gamma = config['gamma']\n",
        "        self.epsilon_start = 1.0\n",
        "        self.epsilon_end = 0.01\n",
        "        self.epsilon_decay = config['epsilon_decay']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.target_update_freq = 100 # Update target net every 100 learning steps\n",
        "        self.steps_done = 0\n",
        "\n",
        "        # Use GPU if available\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Initialize policy and target networks\n",
        "        self.policy_net = QNetwork(state_dim, n_actions).to(self.device)\n",
        "        self.target_net = QNetwork(state_dim, n_actions).to(self.device)\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.target_net.eval()  # Target network is only for evaluation\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)\n",
        "        self.memory = ReplayBuffer(config['memory_size'])\n",
        "\n",
        "        # Log model architecture to W&B\n",
        "        if wandb.run:\n",
        "             wandb.watch(self.policy_net)\n",
        "\n",
        "    def select_action(self, state, exploration=True):\n",
        "        \"\"\"Selects an action using an epsilon-greedy policy.\"\"\"\n",
        "        # Calculate current epsilon\n",
        "        if exploration:\n",
        "            epsilon = self.epsilon_end + (self.epsilon_start - self.epsilon_end) * \\\n",
        "                      math.exp(-1. * self.steps_done / self.epsilon_decay)\n",
        "            self.steps_done += 1\n",
        "        else:\n",
        "            epsilon = 0.0 # No exploration for testing\n",
        "\n",
        "        # Epsilon-greedy selection\n",
        "        if random.random() > epsilon:\n",
        "            with torch.no_grad():\n",
        "                state = torch.tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "                # t.max(1) returns (values, indices)\n",
        "                return self.policy_net(state).max(1)[1].view(1, 1)\n",
        "        else:\n",
        "            return torch.tensor([[random.randrange(self.n_actions)]], device=self.device, dtype=torch.long)\n",
        "\n",
        "    def optimize_model(self):\n",
        "        \"\"\"Performs one step of optimization on the policy network.\"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return None  # Not enough samples in memory\n",
        "\n",
        "        transitions = self.memory.sample(self.batch_size)\n",
        "        batch = Transition(*zip(*transitions))\n",
        "\n",
        "        # Compute a mask of non-final states\n",
        "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                              batch.next_state)), device=self.device, dtype=torch.bool)\n",
        "\n",
        "        # We must check if there are any non-final states\n",
        "        non_final_next_states_list = [torch.tensor(s, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "                                     for s in batch.next_state if s is not None]\n",
        "\n",
        "        state_batch = torch.cat([torch.tensor(s, dtype=torch.float32, device=self.device).unsqueeze(0) for s in batch.state])\n",
        "        action_batch = torch.cat(batch.action)\n",
        "        reward_batch = torch.cat([torch.tensor([r], dtype=torch.float32, device=self.device) for r in batch.reward])\n",
        "\n",
        "        # Compute Q(s_t, a)\n",
        "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "        # Compute V(s_{t+1}) for all next states.\n",
        "        next_state_values = torch.zeros(self.batch_size, device=self.device)\n",
        "\n",
        "        # Only compute next_state_values if there are non-final states\n",
        "        if len(non_final_next_states_list) > 0:\n",
        "            non_final_next_states = torch.cat(non_final_next_states_list)\n",
        "\n",
        "            if self.use_ddqn:\n",
        "                # --- DDQN ---\n",
        "                # 1. Select best action using policy_net\n",
        "                best_actions = self.policy_net(non_final_next_states).max(1)[1].unsqueeze(1)\n",
        "                # 2. Evaluate that action using target_net\n",
        "                next_state_values[non_final_mask] = self.target_net(non_final_next_states).gather(1, best_actions).squeeze().detach()\n",
        "            else:\n",
        "                # --- Standard DQN ---\n",
        "                next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1)[0].detach()\n",
        "\n",
        "        # Compute the expected Q values (Bellman equation)\n",
        "        expected_state_action_values = (next_state_values * self.gamma) + reward_batch\n",
        "\n",
        "        # Compute loss (Smooth L1 Loss)\n",
        "        loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "        # Optimize the model\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100) # Gradient clipping\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def update_target_net(self):\n",
        "        \"\"\"Hard update of the target network's weights.\"\"\"\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "#################################################\n",
        "#  4. Training and Evaluation Function\n",
        "#################################################\n",
        "\n",
        "def train_and_evaluate(config):\n",
        "    \"\"\"\n",
        "    Main function to train and evaluate an agent based on a config dictionary.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize W&B\n",
        "    run = wandb.init(\n",
        "        project=\"DQN_DDQN_MountainCar\", # New project name\n",
        "        config=config,\n",
        "        reinit=True # Allows multiple runs in the same script\n",
        "    )\n",
        "\n",
        "    # Create environment\n",
        "    env = gym.make(\"MountainCar-v0\")\n",
        "\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    n_actions = env.action_space.n\n",
        "\n",
        "    agent = DQNAgent(\n",
        "        state_dim,\n",
        "        n_actions,\n",
        "        config,\n",
        "        use_ddqn=config['use_ddqn']\n",
        "    )\n",
        "\n",
        "    print(f\"--- Starting Run: {run.name} ---\")\n",
        "    print(f\"Config: {config}\")\n",
        "\n",
        "    total_learn_steps = 0\n",
        "\n",
        "    # --- Training Phase ---\n",
        "    for i_episode in range(config['num_episodes']):\n",
        "        state, _ = env.reset()\n",
        "        episode_reward = 0\n",
        "        episode_loss = 0\n",
        "        n_steps = 0\n",
        "\n",
        "        # MountainCar-v0 has a fixed 200-step duration\n",
        "        for t in range(200):\n",
        "            action = agent.select_action(state, exploration=True)\n",
        "            next_state, reward, terminated, truncated, _ = env.step(action.item())\n",
        "            done = terminated or truncated\n",
        "            episode_reward += reward\n",
        "\n",
        "            # Store transition (next_state is None if episode ended)\n",
        "            agent.memory.push(state, action, reward, next_state if not done else None, done)\n",
        "\n",
        "            # Move to the next state\n",
        "            state = next_state\n",
        "\n",
        "            # Perform one step of the optimization\n",
        "            loss = agent.optimize_model()\n",
        "            if loss is not None:\n",
        "                episode_loss += loss\n",
        "                n_steps += 1\n",
        "                total_learn_steps += 1\n",
        "\n",
        "            # Update target network\n",
        "            if total_learn_steps % agent.target_update_freq == 0:\n",
        "                agent.update_target_net()\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        avg_loss = (episode_loss / n_steps) if n_steps > 0 else 0\n",
        "        current_epsilon = agent.epsilon_end + (agent.epsilon_start - agent.epsilon_end) * \\\n",
        "                          math.exp(-1. * agent.steps_done / agent.epsilon_decay)\n",
        "\n",
        "        # Log metrics to W&B\n",
        "        wandb.log({\n",
        "            \"episode\": i_episode,\n",
        "            \"total_reward\": episode_reward, # Will be e.g., -150\n",
        "            \"episode_duration\": t + 1,      # Will be e.g., 150\n",
        "            \"avg_loss\": avg_loss,\n",
        "            \"epsilon\": current_epsilon,\n",
        "            \"steps_done\": agent.steps_done\n",
        "        })\n",
        "\n",
        "        if i_episode % 100 == 0:\n",
        "            print(f\"Episode {i_episode}: Duration = {t+1}, Reward = {episode_reward:.2f}, Avg Loss = {avg_loss:.4f}\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    # --- Testing & Recording Phase ---\n",
        "    print(\"Starting testing and video recording...\")\n",
        "\n",
        "    video_dir = f\"./videos/{run.name}\"\n",
        "    test_env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "    # Record only the first 3 test episodes\n",
        "    test_env = RecordVideo(test_env, video_dir, episode_trigger=lambda e: e < 3)\n",
        "\n",
        "    test_rewards = []\n",
        "    test_durations = []\n",
        "    for i_test in range(100):\n",
        "        state, _ = test_env.reset()\n",
        "        episode_reward = 0\n",
        "        episode_duration = 0\n",
        "        done = False\n",
        "        while not done:\n",
        "            # Select action greedily (no exploration)\n",
        "            action = agent.select_action(state, exploration=False)\n",
        "            next_state, reward, terminated, truncated, _ = test_env.step(action.item())\n",
        "            done = terminated or truncated\n",
        "            episode_reward += reward\n",
        "            episode_duration += 1\n",
        "            state = next_state\n",
        "        test_rewards.append(episode_reward)\n",
        "        test_durations.append(episode_duration)\n",
        "\n",
        "    test_env.close() # Important to save the video\n",
        "\n",
        "    avg_test_reward = np.mean(test_rewards)\n",
        "    avg_test_duration = np.mean(test_durations)\n",
        "\n",
        "    print(f\"Test Results: Avg Duration = {avg_test_duration:.2f}, Avg Reward = {avg_test_reward:.2f}\")\n",
        "\n",
        "    # Log test results and video to W&B\n",
        "    wandb.log({\n",
        "        \"avg_test_reward\": avg_test_reward,\n",
        "        \"avg_test_duration\": avg_test_duration,\n",
        "        # Log the first recorded video\n",
        "        \"video\": wandb.Video(os.path.join(video_dir, \"rl-video-episode-0.mp4\"), fps=30, format=\"mp4\")\n",
        "    })\n",
        "\n",
        "    print(f\"--- Run {run.name} Finished ---\")\n",
        "    run.finish()\n",
        "\n",
        "\n",
        "#################################################\n",
        "#  5. Main Execution\n",
        "#################################################\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define the hyperparameter setups to test\n",
        "    # We will test 4 different configurations\n",
        "\n",
        "    # Config 1: Standard DQN\n",
        "    config1 = {\n",
        "        \"run_name\": \"DQN_fast_decay_small_mem\",\n",
        "        \"use_ddqn\": False,\n",
        "        \"num_episodes\": 1000,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_decay\": 5000,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"memory_size\": 10000,\n",
        "        \"batch_size\": 64\n",
        "    }\n",
        "\n",
        "    # Config 2: Standard DDQN (compare to Config 1)\n",
        "    config2 = {\n",
        "        \"run_name\": \"DDQN_fast_decay_small_mem\",\n",
        "        \"use_ddqn\": True,\n",
        "        \"num_episodes\": 1000,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_decay\": 5000,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"memory_size\": 10000,\n",
        "        \"batch_size\": 64\n",
        "    }\n",
        "\n",
        "    # Config 3: DDQN with slower decay and larger memory\n",
        "    config3 = {\n",
        "        \"run_name\": \"DDQN_slow_decay_large_mem\",\n",
        "        \"use_ddqn\": True,\n",
        "        \"num_episodes\": 1000,\n",
        "        \"gamma\": 0.98, # Different gamma\n",
        "        \"epsilon_decay\": 20000, # Slower decay\n",
        "        \"learning_rate\": 0.0005, # Lower LR\n",
        "        \"memory_size\": 50000, # Larger memory\n",
        "        \"batch_size\": 128 # Larger batch\n",
        "    }\n",
        "\n",
        "    # Config 4: DQN with parameters from Config 3\n",
        "    config4 = {\n",
        "        \"run_name\": \"DQN_slow_decay_large_mem\",\n",
        "        \"use_ddqn\": False,\n",
        "        \"num_episodes\": 1000,\n",
        "        \"gamma\": 0.98,\n",
        "        \"epsilon_decay\": 20000,\n",
        "        \"learning_rate\": 0.0005,\n",
        "        \"memory_size\": 50000,\n",
        "        \"batch_size\": 128\n",
        "    }\n",
        "\n",
        "    # List of all configurations to run\n",
        "    all_configs = [config1, config2, config3, config4]\n",
        "\n",
        "    # Run all experiments\n",
        "    for cfg in all_configs:\n",
        "        train_and_evaluate(cfg)\n",
        "\n",
        "    print(\"All experiments complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pysM3n7Tl3Kn",
        "outputId": "3011c9bc-f21b-45c8-c6df-03c4780edbec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_194535-klbp43bo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/klbp43bo' target=\"_blank\">solar-donkey-1</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/klbp43bo' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/klbp43bo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Run: solar-donkey-1 ---\n",
            "Config: {'run_name': 'DQN_fast_decay_small_mem', 'use_ddqn': False, 'num_episodes': 1000, 'gamma': 0.99, 'epsilon_decay': 5000, 'learning_rate': 0.001, 'memory_size': 10000, 'batch_size': 64}\n",
            "Episode 0: Duration = 200, Reward = -200.00, Avg Loss = 0.0485\n",
            "Episode 100: Duration = 200, Reward = -200.00, Avg Loss = 0.4394\n",
            "Episode 200: Duration = 200, Reward = -200.00, Avg Loss = 0.5902\n",
            "Episode 300: Duration = 153, Reward = -153.00, Avg Loss = 0.4309\n",
            "Episode 400: Duration = 150, Reward = -150.00, Avg Loss = 5.1956\n",
            "Episode 500: Duration = 200, Reward = -200.00, Avg Loss = 59.3080\n",
            "Episode 600: Duration = 200, Reward = -200.00, Avg Loss = 35.3621\n",
            "Episode 700: Duration = 200, Reward = -200.00, Avg Loss = 30.0643\n",
            "Episode 800: Duration = 200, Reward = -200.00, Avg Loss = 11.2681\n",
            "Episode 900: Duration = 153, Reward = -153.00, Avg Loss = 11.4898\n",
            "Training complete.\n",
            "Starting testing and video recording...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: Avg Duration = 156.74, Avg Reward = -156.74\n",
            "--- Run solar-donkey-1 Finished ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆█▇▅▃▂▂▂▅▄▂▂▂▂▂▂▂▂▃▆</td></tr><tr><td>avg_test_duration</td><td>▁</td></tr><tr><td>avg_test_reward</td><td>▁</td></tr><tr><td>episode</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>episode_duration</td><td>███████████████▅▂▁▅▅█▅█████████████████▇</td></tr><tr><td>epsilon</td><td>█▆▅▅▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>steps_done</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>total_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▁█▁▁▁▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>61.4545</td></tr><tr><td>avg_test_duration</td><td>156.74</td></tr><tr><td>avg_test_reward</td><td>-156.74</td></tr><tr><td>episode</td><td>999</td></tr><tr><td>episode_duration</td><td>150</td></tr><tr><td>epsilon</td><td>0.01</td></tr><tr><td>steps_done</td><td>188100</td></tr><tr><td>total_reward</td><td>-150</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">solar-donkey-1</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/klbp43bo' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/klbp43bo</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_194535-klbp43bo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_195521-1w3usi97</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/1w3usi97' target=\"_blank\">sunny-durian-2</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/1w3usi97' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/1w3usi97</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Run: sunny-durian-2 ---\n",
            "Config: {'run_name': 'DDQN_fast_decay_small_mem', 'use_ddqn': True, 'num_episodes': 1000, 'gamma': 0.99, 'epsilon_decay': 5000, 'learning_rate': 0.001, 'memory_size': 10000, 'batch_size': 64}\n",
            "Episode 0: Duration = 200, Reward = -200.00, Avg Loss = 0.0474\n",
            "Episode 100: Duration = 200, Reward = -200.00, Avg Loss = 0.4371\n",
            "Episode 200: Duration = 200, Reward = -200.00, Avg Loss = 0.3684\n",
            "Episode 300: Duration = 200, Reward = -200.00, Avg Loss = 0.4343\n",
            "Episode 400: Duration = 200, Reward = -200.00, Avg Loss = 0.4157\n",
            "Episode 500: Duration = 200, Reward = -200.00, Avg Loss = 0.2366\n",
            "Episode 600: Duration = 109, Reward = -109.00, Avg Loss = 0.0808\n",
            "Episode 700: Duration = 107, Reward = -107.00, Avg Loss = 0.1074\n",
            "Episode 800: Duration = 91, Reward = -91.00, Avg Loss = 0.1333\n",
            "Episode 900: Duration = 93, Reward = -93.00, Avg Loss = 0.1042\n",
            "Training complete.\n",
            "Starting testing and video recording...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: Avg Duration = 119.30, Avg Reward = -119.30\n",
            "--- Run sunny-durian-2 Finished ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁▁▃▄▄▄▅▆▆▅▆█▅▆▅▆▄▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>avg_test_duration</td><td>▁</td></tr><tr><td>avg_test_reward</td><td>▁</td></tr><tr><td>episode</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>episode_duration</td><td>████████████████▃▇█▃▂█▄▂▂▄▂▂▂▂▆▂▅▁▂▅▁▅▅▂</td></tr><tr><td>epsilon</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>steps_done</td><td>▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>total_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄█▅▁▁▅▄▆▄▆▇▇▇▇█▇▇▄▅▅▇▅▁█▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.1496</td></tr><tr><td>avg_test_duration</td><td>119.3</td></tr><tr><td>avg_test_reward</td><td>-119.3</td></tr><tr><td>episode</td><td>999</td></tr><tr><td>episode_duration</td><td>114</td></tr><tr><td>epsilon</td><td>0.01</td></tr><tr><td>steps_done</td><td>152897</td></tr><tr><td>total_reward</td><td>-114</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sunny-durian-2</strong> at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/1w3usi97' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/1w3usi97</a><br> View project at: <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251112_195521-1w3usi97/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_200336-ftcvj7dw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/ftcvj7dw' target=\"_blank\">rich-tree-3</a></strong> to <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/ftcvj7dw' target=\"_blank\">https://wandb.ai/yousefyousefyousef335-cairo-university/DQN_DDQN_MountainCar/runs/ftcvj7dw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Run: rich-tree-3 ---\n",
            "Config: {'run_name': 'DDQN_slow_decay_large_mem', 'use_ddqn': True, 'num_episodes': 1000, 'gamma': 0.98, 'epsilon_decay': 20000, 'learning_rate': 0.0005, 'memory_size': 50000, 'batch_size': 128}\n",
            "Episode 0: Duration = 200, Reward = -200.00, Avg Loss = 0.0732\n"
          ]
        }
      ]
    }
  ]
}